[
  {
    "uid": "EXAMPLE_CHANNEL_MULTI_ITEM_JSON_TTS_1",
    "updateDate": "2016-04-10T00:00:00.0Z",
    "titleText": "Knowledge Diffusion for Neural Dialogue Generation",
    "mainText": "End-to-end neural dialogue generation has shown promising results recently, but it does not employ knowledge to guide the generation and hence tends to generate short, general, and meaningless responses. In this paper, we propose a neural knowledge diffusion (NKD) model to introduce knowledge into dialogue generation. This method can not only match the relevant facts for the input utterance but diffuse them to similar entities. With the help of facts matching and entity diffusion, the neural dialogue generation is augmented with the ability of convergent and divergent thinking over the knowledge base. Our empirical study on a real-world dataset prove that our model is capable of generating meaningful, diverse and natural responses for both factoid-questions and knowledge grounded chi-chats. The experiment results also show that our model outperforms competitive baseline models significantly.",
    "redirectionUrl": "https://acl2018.org/paper/722"
   },
  {
    "uid": "EXAMPLE_CHANNEL_MULTI_ITEM_JSON_TTS_2",
    "updateDate": "2016-04-10T00:00:00.0Z",
    "titleText": "Neural Factor Graph Models for Cross-lingual Morphological Tagging",
    "mainText": "Morphological analysis involves predicting the syntactic traits of a word (e.g. {POS: Noun, Case: Acc, Gender: Fem}). Previous work in morphological tagging improves performance for low-resource languages (LRLs) through cross-lingual training with a high-resource language (HRL) from the same family, but is limited by the strict, often false, assumption that tag sets exactly overlap between the HRL and LRL. In this paper we propose a method for cross-lingual morphological tagging that aims to improve information sharing between languages by relaxing this assumption. The proposed model uses factorial conditional random fields with neural network potentials, making it possible to (1) utilize the expressive power of neural network representations to smooth over superficial differences in the surface forms, (2) model pairwise and transitive relationships between tags, and (3) accurately generate tag sets that are unseen or rare in the training data. Experiments on four languages from the Universal Dependencies Treebank demonstrate superior tagging accuracies over existing cross-lingual approaches.",
    "redirectionUrl": "https://acl2018.org/paper/1502"
  }
]
